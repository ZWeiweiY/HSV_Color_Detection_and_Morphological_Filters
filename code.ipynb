{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "<b>The general objective is to detect blue cursor, yellow timer, and human skin from input video. Your output should be similar to demo.mp4. Please complete steps 1-10 in one single code cell, step 11 in another markdown cell, and upload your Jupyter notebook file (*.ipynb). The whole process can be divided to the following steps:</b>\n",
    "\n",
    "1. (5pts) Input images from video file WiiPlay.mp4 with the same level number as the last two digits of your student id, and show the images in the \"input\" window.\n",
    "\n",
    "2. (5pts) Use <i>cv2.cvtColor()</i> to convert images from BGR to HSV format.\n",
    "\n",
    "3. (10pts) Use <i>cv2.createTrackbar()</i> to create six trackbars (HueMin, HueMax, SatMin SatMax, ValMin, ValMax), and use <i>cv2.getTrackbarPos()</i> to get the current value of each trackbar.\n",
    "\n",
    "4. (10pts) Use <i>cv2.threshold()</i> or <i>cv2.inRange()</i> to apply double thresholding to each channel (Hue, Sat, Val) based on current values of the six trackbars.\n",
    "\n",
    "5. (10pts) Apply morphological filters to remove noise (outliers & holes), and show the detected regions in the \"test\" window.\n",
    "\n",
    "6. (10pts) Find out the best color range to detect <b>blue cursor</b>, apply these thresholds, and show the detected regions in the \"cursor\" window.\n",
    "\n",
    "7. (10pts) Find out the best color range to detect <b>yellow timer</b>, apply these thresholds, and show the detected regions in the \"timer\" window.\n",
    "\n",
    "8. (10pts) Find out the best color range to detect <b>human skin</b>, apply these thresholds, and show the detected regions in the \"skin\" window.\n",
    "\n",
    "9. (10pts) Use <i>cv2.connectedComponents()</i> and <i>cv2.putText()</i> to count and display how many skin regions in each frame.\n",
    "\n",
    "10. (10pts) Show each individual skin region using different color.\n",
    "\n",
    "11. (10pts) Which steps you believe you have completed? Which steps bother you?\n",
    "\n",
    "\n",
    "<b>WiiPlay.mp4</b> input file click [here](https://drive.google.com/file/d/15XSgfwoPRxu48nUm49mNCqHVXlepLxLN/view?usp=share_link)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore',invalid='ignore')\n",
    "\n",
    "def hMaxCallback(pos):\n",
    "    pass\n",
    "def hMinCallback(pos):\n",
    "    pass\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('WiiPlay.mp4')\n",
    "# Check if the video file is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open the video file\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" 1. Input images from video file WiiPlay.mp4 with the same level number as the last two digits of your student id. \"\"\"\n",
    "\n",
    "# Each video has different time length and frame rate.\n",
    "# frame_seq = start_time * fps\n",
    "# time_length = seconds * fps\n",
    "time_length = 900.0\n",
    "fps = 30\n",
    "frame_seq = 2940\n",
    "out_size = (640, 360)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq);\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" Show the images in the \"input\" window. \"\"\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    \n",
    "    cur_frame = cv2.resize(frame, out_size, 0, 0, interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow('Input', cur_frame)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" 2. Use cv2.cvtColor() to convert images from BGR to HSV format. \"\"\"\n",
    "\n",
    "    hsv_frame = cv2.cvtColor(cur_frame, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('HSV', hsv_frame)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" 3. Use cv2.createTrackbar() to create six trackbars: (HueMin, HueMax, SatMin SatMax, ValMin, ValMax) \"\"\"\n",
    "\n",
    "    cv2.namedWindow('Test')\n",
    "\n",
    "    cv2.createTrackbar('HueMin', 'Test',    0, 179, hMinCallback)\n",
    "    cv2.createTrackbar('HueMax', 'Test',  179, 179, hMaxCallback) \n",
    "    cv2.createTrackbar('SatMin', 'Test',    0, 255, hMinCallback)\n",
    "    cv2.createTrackbar('SatMax', 'Test',  255, 255, hMaxCallback) \n",
    "    cv2.createTrackbar('ValMin', 'Test',    0, 255, hMinCallback)\n",
    "    cv2.createTrackbar('ValMax', 'Test',  255, 255, hMaxCallback) \n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Use cv2.getTrackbarPos() to get the current value of each trackbar. \"\"\"\n",
    "\n",
    "    hMax = cv2.getTrackbarPos('HueMax','Test')\n",
    "    hMin = cv2.getTrackbarPos('HueMin','Test')\n",
    "    sMax = cv2.getTrackbarPos('SatMax','Test')\n",
    "    sMin = cv2.getTrackbarPos('SatMin','Test')\n",
    "    vMax = cv2.getTrackbarPos('ValMax','Test')\n",
    "    vMin = cv2.getTrackbarPos('ValMin','Test')\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" 4. Use cv2.threshold() or cv2.inRange() to apply double thresholding to each channel (Hue, Sat, Val) \"\"\"\n",
    "    \"\"\" Based on current values of the six trackbars \"\"\"\n",
    "\n",
    "    upper = np.array([hMax, sMax, vMax])\n",
    "    lower = np.array([hMin, sMin, vMin])\n",
    "    \n",
    "    mask = cv2.inRange(cur_frame, lower, upper)\n",
    "    # masked_frame = cur_frame\n",
    "    # masked_frame[mask == 0] = 0\n",
    "    # cv2.imshow('Test', masked_frame)\n",
    "    # cv2.imshow('Test', mask)\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\" 5. Apply morphological filters to remove noise (outliers & holes). \"\"\"\n",
    "\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    \n",
    "    # img_erosion = cv2.erode(cur_frame, kernel, iterations=1)\n",
    "    # img_dilation = cv2.dilate(cur_frame, kernel, iterations=1)\n",
    "    img_opening = cv2.morphologyEx(cur_frame, cv2.MORPH_OPEN, kernel)\n",
    "    # img_closing = cv2.morphologyEx(cur_frame, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    masked_frame = cv2.inRange(img_opening, lower, upper)\n",
    "\n",
    "    \"\"\" Show the detected regions in the \"test\" window. \"\"\"\n",
    "    \n",
    "    cv2.imshow('Test', masked_frame)\n",
    "    \n",
    "\n",
    "     \n",
    "    \"\"\" 6. Find out the best color range to detect blue cursor, apply these thresholds \"\"\"\n",
    "    \n",
    "    cursor_lower = np.array([100,100,100]) \n",
    "    cursor_upper = np.array([124, 255, 255]) \n",
    "    cursor_mask = cv2.inRange(hsv_frame,cursor_lower,cursor_upper) \n",
    "\n",
    "    \"\"\" Show the detected regions in the \"cursor\" window. \"\"\"\n",
    "\n",
    "    cv2.imshow('Cursor',cursor_mask)\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\" 7. Find out the best color range to detect yellow timer, apply these thresholds \"\"\" \n",
    "    \n",
    "    timer_lower = np.array([22,80,70]) \n",
    "    timer_upper = np.array([34, 255, 255]) \n",
    "    timer_mask = cv2.inRange(hsv_frame,timer_lower,timer_upper) \n",
    "\n",
    "    \"\"\" Show the detected regions in the \"timer\" window. \"\"\"\n",
    "\n",
    "    cv2.imshow('Timer',timer_mask)\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\" 8. Find out the best color range to detect human skin, apply these thresholds \"\"\"\n",
    "    \n",
    "    skin_lower = np.array([10,28,100]) \n",
    "    skin_upper = np.array([16, 255, 255]) \n",
    "    skin_mask = cv2.inRange(hsv_frame,skin_lower,skin_upper) \n",
    "\n",
    "    \"\"\" Show the detected regions in the \"skin\" window. \"\"\"\n",
    "\n",
    "    cv2.imshow('Skin',skin_mask)\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\" 9. Use cv2.connectedComponents() and cv2.putText() to count and display how many skin regions in each frame. \"\"\"\n",
    "    \n",
    "    _, skin_maskDisplay = cv2.threshold(skin_mask, 200, 255, cv2.THRESH_BINARY)\n",
    "    _, bin_img = cv2.threshold(skin_mask, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    _, labels = cv2.connectedComponents(skin_maskDisplay)\n",
    "    ret, _ = cv2.connectedComponents(bin_img)\n",
    "    \n",
    "    # Noise adjustments\n",
    "    ret = ret - 2\n",
    "    # print(ret)\n",
    "        \n",
    "    \"\"\" 10. Show each individual skin region using different color. \"\"\"\n",
    "    \n",
    "    # Hue controls the color\n",
    "    label_hue = np.uint8(179 * labels / np.max(labels))\n",
    "    \n",
    "    # Saturation and Value set to same size blank array\n",
    "    blank_channel = 255 * np.ones_like(label_hue)\n",
    "    \n",
    "    # Merge HSV\n",
    "    labeled_img = cv2.merge([label_hue, blank_channel, blank_channel])\n",
    "\n",
    "    # Convert to BGR for display\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Set bg(background) label to black\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    \n",
    "    # Setup text (text must be string)\n",
    "    regions = str(ret)\n",
    "    WHITE_BGR = (255, 255, 255)\n",
    "    cv2.putText(labeled_img, regions , (0,300), cv2.FONT_HERSHEY_SIMPLEX, 2, WHITE_BGR , 4, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Count and Display',labeled_img)\n",
    "    \n",
    "\n",
    "\n",
    "    # stop til time_length = 0 \n",
    "    time_length = time_length - 1\n",
    "    if time_length == 0:\n",
    "        break\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 32:\n",
    "        cv2.waitKey()\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. (10pts) Which steps you believe you have completed? Which steps bother you?\n",
    "\n",
    "I believe I completed all the steps. The most bothering step for me among all is the skin mask display. I use the inRange function to apply double thresholding, calculate the range of skin color, but it detects other colors which are in the same range of human skin. This effects the skin amount with some noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
